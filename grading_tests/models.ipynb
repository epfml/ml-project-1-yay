{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-28T15:16:38.657650736Z",
          "start_time": "2023-10-28T15:16:38.400100674Z"
        },
        "id": "wgiVX3FT1yZ6",
        "outputId": "29d239ad-b7bb-46aa-98e8-910407e35aa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/')\n",
        "from helpers import *\n",
        "from implementations import *"
      ],
      "metadata": {
        "id": "dUD1zNZs-Nas"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "is_executing": true,
        "ExecuteTime": {
          "start_time": "2023-10-28T15:16:39.808155267Z"
        },
        "id": "d6pdfCp31yZ-"
      },
      "outputs": [],
      "source": [
        "# loading the data\n",
        "data_path = '/content/drive/MyDrive/Colab Notebooks/dataset_to_release'\n",
        "x_train_preclean, x_test_preclean, y_train, train_ids, test_ids = load_csv_data(data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeRMsoy01yZ-"
      },
      "source": [
        "# Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-28T12:34:36.866961011Z",
          "start_time": "2023-10-28T12:34:36.231419968Z"
        },
        "id": "XVrzvvRY1yaC",
        "outputId": "84d7c2b7-4b88-4a6c-cd52-571690ab4eb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(328135, 321)\n"
          ]
        }
      ],
      "source": [
        "print(x_train_preclean.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def transform_train(feature):\n",
        "    m = dict()\n",
        "    for x in feature:\n",
        "        if x not in m:\n",
        "            m[x] = len(m)\n",
        "    f = np.vstack((np.eye(len(m)), np.zeros(len(m))))\n",
        "    u = f[np.vectorize(lambda key: m.get(key, len(m)))(feature)]\n",
        "    return u, m\n",
        "\n",
        "\n",
        "def transform_test(feature, m):\n",
        "    n_uniq = len(m)\n",
        "    f = np.vstack((np.eye(n_uniq), np.zeros(n_uniq)))\n",
        "    ind = np.array([m[k] if k in m else n_uniq for k in feature])\n",
        "    return f[ind]\n",
        "\n",
        "\n",
        "def percentageFilled(data):\n",
        "    return 1 - np.isnan(data).sum() / len(data)\n",
        "\n",
        "\n",
        "def threshold_col_filter(data, threshold):\n",
        "    percentage_filled = np.apply_along_axis(percentageFilled, 0, data)\n",
        "    return percentage_filled > threshold\n",
        "\n",
        "\n",
        "def non_constant_filter(data):\n",
        "    return np.logical_not(np.logical_or(np.isnan(np.nanstd(data, 0)), np.nanstd(data, 0) == 0))\n",
        "\n",
        "\n",
        "cat_threshold = 10\n",
        "\n",
        "def standardize(x):\n",
        "    \"\"\"Standardize the original data set.\"\"\"\n",
        "    std = np.nanstd(x, axis=0)\n",
        "    mean = np.nanmean(x, axis=0)\n",
        "    return np.nan_to_num((x - np.nanmean(x, axis=0)) / np.nanstd(x, axis=0)), mean, std\n",
        "\n",
        "\n",
        "def process_train(data):\n",
        "    n, m = data.shape\n",
        "    filter = np.logical_and(threshold_col_filter(data, 0.2), non_constant_filter(data))\n",
        "    categorical_filter = np.apply_along_axis(lambda x: len(set(x)) < cat_threshold, 0, data)\n",
        "    cat_transform = dict()\n",
        "    num_transform = dict()\n",
        "    res = np.empty((n, 0))\n",
        "    for i in range(m):\n",
        "        if not filter[i]:\n",
        "            continue\n",
        "        if categorical_filter[i]:\n",
        "            encoded, mp = transform_train(data[:, i])\n",
        "            cat_transform[i] = mp\n",
        "            res = np.append(res, encoded, axis=1)\n",
        "        else:\n",
        "            x_num_std, mean, std = standardize(data[:, i])\n",
        "            x_num_std[abs(x_num_std) > 3] = 0\n",
        "            num_transform[i] = (mean, std)\n",
        "            res = np.append(res, x_num_std.reshape((n,1)), axis=1)\n",
        "    return res, filter, categorical_filter, num_transform, cat_transform\n",
        "\n",
        "\n",
        "def process_test(data, filter, categorical_filter, num_transform, cat_transform):\n",
        "    n, m = data.shape\n",
        "    res = np.empty((n, 0))\n",
        "    for i in range(m):\n",
        "        if not filter[i]:\n",
        "            continue\n",
        "        if categorical_filter[i]:\n",
        "            res = np.append(res, transform_test(data[:, i], cat_transform[i]), axis=1)\n",
        "        else:\n",
        "            mean, std = num_transform[i] # std shouldn't be 0\n",
        "            res = np.append(res, np.nan_to_num((data[:, i] - mean) / std).reshape((n,1)), axis=1)\n",
        "    return res\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wqWLxaVY5dYZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, filter, categorical_filter, num_transform, cat_transform = process_train(x_train_preclean)\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "S6SGW4pf5di6",
        "outputId": "c66a113e-91cf-48cf-ba79-1e9abc0c1c5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(328135, 428)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = process_test(x_test_preclean, filter, categorical_filter, num_transform, cat_transform)\n",
        "print(x_test.shape)\n"
      ],
      "metadata": {
        "id": "PMH65FUi5dmk",
        "outputId": "207a04fb-d9d1-46ce-e0aa-0e3c880f3994",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(109379, 428)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "txq7AT-i5dtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic regression with regularization**"
      ],
      "metadata": {
        "id": "NO38t5177Jt5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T16:50:08.250080582Z",
          "start_time": "2023-10-27T16:50:08.205100158Z"
        },
        "id": "jHsQp9bS7GiX"
      },
      "outputs": [],
      "source": [
        "\n",
        "def logistic_gradient(y, tx, w):\n",
        "    return  tx.T.dot(sigmoid(tx.dot(w)) - y)/ len(y)\n",
        "def compute_gradient_logistic_loss_regularized(y, tx, w, lambda_):\n",
        "    \"\"\"Compute the gradient of the regularized logistic regression \"\"\"\n",
        "    grad = logistic_gradient(y, tx, w) + lambda_ * w\n",
        "    return grad\n",
        "\n",
        "def regularized_log_reg_sgd(y, tx, initial_w, max_iters, gamma,  lambda_ ):\n",
        "    \"\"\"Regularized logistic regression using stochastic gradient descent.\"\"\"\n",
        "    w = initial_w\n",
        "    prev_loss = float('inf')\n",
        "\n",
        "    for n_iter in range(max_iters):\n",
        "\t\t# Each iteration corresponds to one epoch (num_batches=len(y)) and each batch has size 1\n",
        "        for batch_y, batch_x in batch_iter(y, tx, 1, num_batches=len(y)):\n",
        "\t\t\t# Computing the gradient of the logistic loss with respect to w\n",
        "            gradient = compute_gradient_logistic_loss_regularized(batch_y, batch_x, w, lambda_)\n",
        "\t\t\t# Updating w\n",
        "            w -= gamma * gradient\n",
        "\n",
        "\n",
        "        loss = logistic_loss(y, tx, w) + (lambda_ / 2) * np.squeeze(w.T @ w)\n",
        "        if prev_loss <= loss:\n",
        "            gamma *= 0.1  # adapt step size\n",
        "        prev_loss = loss\n",
        "\n",
        "    return w, loss\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model paramaters (not optimized yet)\n",
        "initial_w = np.zeros(x_train.shape[1], dtype=np.float64)\n",
        "max_iters = 100\n",
        "gamma = 0.01\n",
        "lambda_ = 0.0001\n",
        "\n",
        "w, loss = regularized_log_reg_sgd(y_train, x_train, initial_w, max_iters, gamma, lambda_)"
      ],
      "metadata": {
        "id": "Up865Z9_5d1n"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-28T12:34:38.978656103Z",
          "start_time": "2023-10-28T12:34:36.869415110Z"
        },
        "id": "oix7Goav1yaC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9348e36-e7e1-4c8a-e666-92bb909c1d7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss =  0.2211336812499828\n"
          ]
        }
      ],
      "source": [
        "print('loss = ', loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T19:57:29.290241071Z",
          "start_time": "2023-10-27T19:57:29.287028223Z"
        },
        "id": "6B1stdhJAGxB"
      },
      "outputs": [],
      "source": [
        "def prediction_labels(weights, data):\n",
        "    \"\"\"Generates class predictions given weights, and a test data matrix.\"\"\"\n",
        "    y_pred = sigmoid(np.dot(data, weights))\n",
        "    # display(y_pred)\n",
        "    y_pred[np.where(y_pred >= 0.5)] = 1\n",
        "    y_pred[np.where(y_pred < 0.5)] = 0\n",
        "    return y_pred\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "temp (328135,)\n"
          ]
        }
      ],
      "source": [
        "y_pred = prediction_labels(w, x_train)\n",
        "temp = y_pred[y_pred != -1]\n",
        "print(\"temp\", temp.shape)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T19:57:31.240908682Z",
          "start_time": "2023-10-27T19:57:31.216234202Z"
        },
        "outputId": "84192a6b-4c67-4f19-ff4d-bdcd11f673c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh0dFXRCAGxF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T19:58:10.480692069Z",
          "start_time": "2023-10-27T19:58:10.437001412Z"
        },
        "outputId": "d3f9e248-f75f-4802-f746-f6143b0baa72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxDNJfvIAGxI"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.9146905999055267\n"
          ]
        }
      ],
      "source": [
        "accuracy = (y_pred == y_train).sum() / len(y_train)\n",
        "print(\"accuracy\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**predicting x_test**"
      ],
      "metadata": {
        "id": "BEt2Rmi1_7hW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = prediction_labels(w, x_test)\n",
        "y_pred_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDxHpeh6AZSD",
        "outputId": "5f2773d3-04e7-4bba-939d-ef516698a015"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109379,)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_pred, y_train):\n",
        "    return (y_pred == y_train).sum() / len(y_train)\n",
        "def precision(y_pred, y_train):\n",
        "    TP = np.sum((y_train==1) & (y_pred==1))\n",
        "    FP = np.sum((y_train==0) & (y_pred==1))\n",
        "    return TP/(TP+FP)\n",
        "def recall(y_pred, y_train):\n",
        "    recall = np.sum((y_train==1) & (y_pred==1)) / np.sum(y_train==1)\n",
        "    return recall\n",
        "def f_score (y_pred, y_train):\n",
        "    return 2*precision(y_pred, y_train)*recall(y_pred, y_train) / (precision(y_pred, y_train) + recall(y_pred, y_train))\n",
        "\n",
        "print(\"accuracy\", accuracy(y_pred, y_train))\n",
        "print(\"precision\", precision(y_pred, y_train))\n",
        "print(\"recall\", recall(y_pred, y_train))\n",
        "print(\"f_score\", f_score(y_pred, y_train))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-smN1koFEr1l",
        "outputId": "13c4a9bc-a3ba-409e-de47-3eaa176f9c0b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.9146905999055267\n",
            "precision 0.56360103626943\n",
            "recall 0.1501639344262295\n",
            "f_score 0.23714402507153565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TZnHbMRTErwl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QMbW5en-EruV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_k_indices(y, k_fold, seed):\n",
        "    \"\"\"build k indices for k-fold.\n",
        "\n",
        "    Args:\n",
        "        y:      shape=(N,)\n",
        "        k_fold: K in K-fold, i.e. the fold num\n",
        "        seed:   the random seed\n",
        "\n",
        "    Returns:\n",
        "        A 2D array of shape=(k_fold, N/k_fold) that indicates the data indices for each fold\n",
        "\n",
        "    >>> build_k_indices(np.array([1., 2., 3., 4.]), 2, 1)\n",
        "    array([[3, 2],\n",
        "           [0, 1]])\n",
        "    \"\"\"\n",
        "    num_row = y.shape[0]\n",
        "    interval = int(num_row / k_fold)\n",
        "    np.random.seed(seed)\n",
        "    indices = np.random.permutation(num_row)\n",
        "    k_indices = [indices[k * interval : (k + 1) * interval] for k in range(k_fold)]\n",
        "    return np.array(k_indices)"
      ],
      "metadata": {
        "id": "EZgTkZPiEroY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validation(y, x, k_fold, lambda_):\n",
        "    \"\"\"\n",
        "    Separate the training set into k_fold parts, get k_fold sets of w weights, and return the average w\n",
        "    Args:\n",
        "        y,\n",
        "        x,\n",
        "        k_fold,\n",
        "        lambda_,\n",
        "\n",
        "    Return:\n",
        "        average weight\n",
        "        losses (loss of each fold)\n",
        "    \"\"\"\n",
        "    k_indices = build_k_indices(y, k_fold, 1)\n",
        "    losses = []\n",
        "    weights = []\n",
        "    for k in range(k_fold):\n",
        "        test_indices = k_indices[k]\n",
        "        train_indices = k_indices[~(np.arange(k_indices.shape[0]) == k)].flatten()\n",
        "        x_train = x[train_indices]\n",
        "        y_train = y[train_indices]\n",
        "        x_test = x[test_indices]\n",
        "        y_test = y[test_indices]\n",
        "\n",
        "        w, loss = regularized_log_reg_sgd(y_train, x_train, lambda_, np.zeros(x_train.shape[1]), 100, 0.1)\n",
        "        losses.append(loss)\n",
        "        weights.append(w)\n",
        "\n",
        "    return np.mean(weights, axis=0), losses"
      ],
      "metadata": {
        "id": "TH4x0EW0Erip"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_parameters(y, tx, intitial_w, max_iters, gamma, k_fold, lambdas):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "        y:\n",
        "        tx:\n",
        "        intitial_w:\n",
        "        max_iters:\n",
        "        gamma:\n",
        "        lambdas:\n",
        "        k_fold:\n",
        "\n",
        "    Returns: best lambda parameter\n",
        "\n",
        "    \"\"\"\n",
        "    seed = 55\n",
        "    # split data in k fold\n",
        "    k_indices = build_k_indices(y, k_fold, seed)\n",
        "\n",
        "\n",
        "    rmse_tr = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for lambda_ in lambdas:\n",
        "        rmsetr_tmp = []\n",
        "        f1_tmp = []\n",
        "        for k in range(k_fold):\n",
        "            # make cross validation return weight\n",
        "            w, loss = cross_validation(y,tx, k_indices, lambda_)\n",
        "            rmsetr_tmp.append(loss)\n",
        "            y_pred = prediction_labels(w, tx)\n",
        "            f1_tmp.append(f1_score(y_pred, y))\n",
        "\n",
        "        rmse_tr.append(np.mean(rmsetr_tmp))\n",
        "        f1_scores.append(np.mean(f1_tmp))\n",
        "    best_lambda, best_rmse, best_f1  = lambdas[np.argmin(rmse_tr)], np.min(rmse_tr), np.min(f1_scores)\n",
        "    print( \"The best rmse of %.3f is obtained for a lambda of %.5f.\"%(best_rmse, best_lambda))\n",
        "    print(\"The best f1-score of %.3f is obtained for a lambda of %.5f.\"%(best_f1, best_lambda))\n",
        "    return best_lambda"
      ],
      "metadata": {
        "id": "8TXYdwVMErZY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_lambda = get_best_parameters(y_train, x_train, initial_w, max_iters, gamma, k_fold=2, lambdas= np.logspace(-4, 0, 30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "vecBwpasErWj",
        "outputId": "97005a55-4e91-4ae1-f7eb-e5dbd2a825c6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-3d072a015080>:17: RuntimeWarning: divide by zero encountered in divide\n",
            "  interval = int(num_row / k_fold)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-64b243d88585>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_lambda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-9106ebea99f3>\u001b[0m in \u001b[0;36mget_best_parameters\u001b[0;34m(y, tx, intitial_w, max_iters, gamma, k_fold, lambdas)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# make cross validation return weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mrmsetr_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-2ce740d262b7>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(y, x, k_fold, lambda_)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0mof\u001b[0m \u001b[0meach\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \"\"\"\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mk_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_k_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-3d072a015080>\u001b[0m in \u001b[0;36mbuild_k_indices\u001b[0;34m(y, k_fold, seed)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \"\"\"\n\u001b[1;32m     16\u001b[0m     \u001b[0mnum_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0minterval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_row\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-28T12:47:14.939434484Z",
          "start_time": "2023-10-28T12:47:14.891651391Z"
        },
        "id": "1m7XgU1X1yaF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jEgu8dNXHQMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Old Stuff"
      ],
      "metadata": {
        "id": "8D80vxr5HKrG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "array([[2.53290043, 2.53290043, 0.28398752, ..., 0.34718589, 0.26522141,\n        0.41168639],\n       [0.19675462, 0.19675462, 0.24309477, ..., 0.        , 0.        ,\n        0.        ],\n       [0.10699903, 0.10699903, 4.20921724, ..., 0.34718589, 0.26522141,\n        0.41168639],\n       ...,\n       [0.07267939, 0.07267939, 0.1885711 , ..., 0.34718589, 0.26522141,\n        0.41168639],\n       [0.18170048, 0.18170048, 0.22037657, ..., 0.28798285, 0.26522141,\n        0.36772918],\n       [0.97641325, 0.97641325, 0.26581296, ..., 0.34718589, 0.26522141,\n        0.41168639]])"
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "subset_idx =[7, 8, 62, 219, 220, 222, 226, 229, 252, 253, 264, 276, 277, 295, 296, 299, 300, 301, 302, 303, 304]\n",
        "\n",
        "subset = x_train_preclean[:, subset_idx]\n",
        "subset = standardize(subset)\n",
        "subset"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-28T14:03:32.351584131Z",
          "start_time": "2023-10-28T14:03:32.166422350Z"
        },
        "id": "N-QLVs__1yaF",
        "outputId": "e1491611-7518-4143-b846-18113481f70c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outliers for Numerical valued"
      ],
      "metadata": {
        "collapsed": false,
        "id": "8ebvK-Db1yaG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-43614186a432>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# find the indices of these columns in the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'subset' is not defined"
          ]
        }
      ],
      "source": [
        "# find the indices of these columns in the data\n",
        "import matplotlib.pyplot as plt\n",
        "x = subset\n",
        "x_std = np.nan_to_num((x - np.nanmean(x, axis=0)) / np.nanstd(x, axis=0))\n",
        "\n",
        "\n",
        "def box_plot(x, feature_column):\n",
        "    \"\"\"\n",
        "    Illustrating box-plot for a specific feature and printing indices of samples that can be outliers.\n",
        "    \"\"\"\n",
        "    plt.boxplot(x[:, feature_column], showfliers=True)\n",
        "    plt.title('feature column:' + str(feature_column))\n",
        "    plt.show()\n",
        "    index_to_delete = np.where(x[:, feature_column] == max(x[:, feature_column]))[0][0]\n",
        "    print('sample (potential) outlier index:', index_to_delete)\n",
        "\n",
        "\n",
        "def box_multi_plot(x):\n",
        "    \"\"\"\n",
        "    Plotting the boxplots for all features\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(20, 15))\n",
        "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "    for featureID in range(x.shape[1]):\n",
        "        ax = fig.add_subplot(6, 5, featureID + 1)\n",
        "        ax.boxplot(x[:, featureID], showfliers=True)\n",
        "        ax.grid(axis='y', alpha=0.75)\n",
        "        ax.set(title='Feature column:{}'.format(featureID))\n",
        "def hist_multi_plot(x, color):\n",
        "    \"\"\"\n",
        "    Plotting the histograms of each feature in a design matrix 'tx'.\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(30, 25))\n",
        "    fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
        "    for featureID in range(x.shape[1]):\n",
        "        ax = fig.add_subplot(6, 5, featureID + 1)\n",
        "        ax.hist(x=x[:, featureID], bins='auto', color=color)\n",
        "        ax.grid(axis='y', alpha=1)\n",
        "        ax.set(title='Feature column:{}'.format(featureID))\n",
        "    plt.show()\n",
        "\n",
        "#hist_multi_plot(x_std, color='blue')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-28T14:05:34.483454190Z",
          "start_time": "2023-10-28T14:03:58.833939251Z"
        },
        "id": "PeoCOHG_1yaG",
        "outputId": "c6322ffb-9bef-4491-c02c-7414c848436f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "source": [
        "#box_multi_plot(x_std)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-28T14:08:25.260163648Z",
          "start_time": "2023-10-28T14:08:23.474755486Z"
        },
        "id": "JTlYjZL31yaG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# filter out the outliers\n",
        "def remove_outliers(x_num, threshold = 3):\n",
        "\n",
        "    x = x_num.copy()\n",
        "    removed_count = 0\n",
        "    for col in range(x.shape[1]):\n",
        "        std = np.std(x[:, col])\n",
        "        range_ = [-threshold*std, threshold*std]\n",
        "        # Count outliers for this column\n",
        "        removed_count_col = np.sum((x[:, col] < range_[0]) | (x[:, col] > range_[1]))\n",
        "        removed_count += removed_count_col\n",
        "\n",
        "        # Keep only values within the range\n",
        "        x[np.logical_or(x[:, col] < range_[0], x[:, col] > range_[1])] = 0\n",
        "\n",
        "    return x, removed_count\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-28T15:16:30.336420214Z",
          "start_time": "2023-10-28T15:16:30.328684869Z"
        },
        "id": "QCaNaDzF1yaG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'x_std' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_35946/2039962237.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_outliers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_std' is not defined"
          ]
        }
      ],
      "source": [
        "result, c = remove_outliers(x_std)\n",
        "print(c / (x_std.shape[0] * x_std.shape[1]))\n",
        "result"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-28T15:16:31.355513305Z",
          "start_time": "2023-10-28T15:16:31.347477580Z"
        },
        "id": "PPKzdIRD1yaG",
        "outputId": "276ba549-0319-43eb-8d0e-63903417714d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "source": [
        "#box_multi_plot(result)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-28T14:31:06.515104443Z",
          "start_time": "2023-10-28T14:31:05.415785501Z"
        },
        "id": "f6QwFQXe1yaH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "ia_RAMRX1yaH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "gpVrHW_H1yaH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCL-v8az1yaH"
      },
      "source": [
        "# Logistic regression *without* regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logisitc regression different than the one in implementations.py. uses stochastic gradient descent. Slight modifications to sigmoid and loss to not make an overflow."
      ],
      "metadata": {
        "collapsed": false,
        "id": "N_yDAqeK1yaH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def sigmoid(t):\n",
        "    t = np.clip(t, -709, 709)  # Clip to avoid overflow. exp(709) is close to the maximum representable float64\n",
        "    return np.where(t < 0, np.exp(t)/(1.0 +np.exp(t)) , 1.0 / (1.0 + np.exp(-t)))\n",
        "def logistic_loss(y, tx, w):\n",
        "    epsilon = 0.000000001\n",
        "    y_hat = sigmoid(tx.dot(w))\n",
        "    y_hat = np.clip(y_hat, epsilon, 1-epsilon)\n",
        "    loss = - np.average(y*np.log(y_hat) + (1-y)*np.log(1-y_hat))\n",
        "    return loss\n",
        "\n",
        "def logistic_gradient(y, tx, w):\n",
        "    return  tx.T.dot(sigmoid(tx.dot(w)) - y)/ len(y)\n",
        "\n",
        "\n",
        "def logistic_regression_step(y, tx, initial_w, max_iters, gamma):\n",
        "    w = initial_w\n",
        "    prev_loss = float('inf')\n",
        "\n",
        "    for n_iter in range(max_iters):\n",
        "       for batch_y, batch_x in batch_iter(y, tx, 1, num_batches=len(tx)):\n",
        "          gradient = logistic_gradient(batch_y, batch_x, w)\n",
        "          w = w - gamma * gradient\n",
        "\n",
        "       loss = logistic_loss(y, tx, w)\n",
        "       if prev_loss <= loss:\n",
        "          gamma *= 0.1        # control of the step size\n",
        "       prev_loss = loss\n",
        "       #print(\"SGD iter. {bi}/{ti}: loss={l}, w={}\".format(   bi=n_iter, ti=max_iters - 1, l=loss, w=w))\n",
        "\n",
        "    return w, loss"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T19:43:45.128570767Z",
          "start_time": "2023-10-27T19:43:45.124241051Z"
        },
        "id": "icw3crax1yaH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T19:43:53.027172684Z",
          "start_time": "2023-10-27T19:43:53.017581669Z"
        },
        "id": "uDNEsfwP1yaI"
      },
      "outputs": [],
      "source": [
        "initial_w = np.zeros(x_train_std.shape[1], dtype=np.float64) # float64 can be faster and more stable to overflow issues appearantly\n",
        "max_iters = 100\n",
        "gamma = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T19:56:30.673559521Z",
          "start_time": "2023-10-27T19:43:54.973447960Z"
        },
        "id": "DVMj66O-1yaI"
      },
      "outputs": [],
      "source": [
        "\n",
        "w, loss = logistic_regression_step(y_train, x_train_std, initial_w, max_iters, gamma)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T19:57:18.280795826Z",
          "start_time": "2023-10-27T19:57:18.236452608Z"
        },
        "id": "7MiSUkT41yaI",
        "outputId": "9dcea782-2487-44e1-e440-53663301cf4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss is  0.22924340476877145\n",
            "w is  [-3.27714283e+00  5.97358740e-03  1.56328367e-02  1.09390716e-02\n",
            " -1.01284227e-02  2.24112448e-02 -2.30569832e-02  0.00000000e+00\n",
            "  0.00000000e+00 -5.13949071e-01  4.10297682e-02  0.00000000e+00\n",
            " -1.70812189e-01  0.00000000e+00 -2.41542597e-02  6.15125785e-03\n",
            "  1.14175303e-02  5.94134381e-01 -7.39418409e-02 -4.76007255e-03\n",
            " -2.10028480e-02 -2.76006599e-03  3.63636231e-02 -3.96158969e-02\n",
            "  1.01179566e-02 -2.01473154e-01 -8.30796054e-02 -2.80547196e-01\n",
            " -2.52487516e-01 -2.50054271e-01 -1.34269832e-01 -1.64759702e-02\n",
            " -2.36521036e-02  1.09567745e-02 -5.90979124e-02 -3.19943082e-02\n",
            " -2.01536670e-02 -5.30932673e-02 -9.71013368e-02 -5.02039207e-02\n",
            " -1.42322480e-02  3.40141487e-02 -1.84255016e-02  2.26267116e-03\n",
            " -1.14936679e-01  1.35321426e-01 -5.64887148e-03 -2.71442679e-02\n",
            "  3.23787539e-02 -4.54569961e-02 -1.57900825e-02 -3.70927422e-02\n",
            " -3.69578301e-02 -2.20893986e-02 -4.73067695e-03 -3.25744003e-02\n",
            "  1.81063129e-02  3.91958186e-03 -1.08893002e-01 -1.37895984e-01\n",
            " -6.10165439e-03  1.23568858e-02  8.98930094e-02  5.70066061e-03\n",
            "  7.70949141e-02  5.04885317e-03 -4.71545284e-03  7.93441572e-03\n",
            "  1.36270526e-02  3.86953787e-02 -5.08600085e-03 -1.12480116e-02\n",
            "  1.57498712e-02  8.47206091e-03  1.43550487e-02  6.21139023e-03\n",
            "  2.03572131e-02  1.68089160e-02  2.63680063e-02 -3.47947123e-03\n",
            " -1.45595602e-02 -3.71198978e-03  6.31685310e-03  1.15290144e-02\n",
            "  5.63159865e-02 -1.15400444e-02 -3.61276229e-03 -1.05754295e-02\n",
            " -1.18128665e-01  1.19144688e-02 -1.63894586e-02 -3.50470946e-02\n",
            " -2.12055140e-01  5.63101387e-02  7.81421935e-04 -4.78001975e-02\n",
            "  4.75759118e-02 -2.14486327e-02  3.05631498e-02 -4.90956626e-03\n",
            " -3.46966842e-02 -6.39156550e-03  6.61200940e-03 -1.12742803e-01\n",
            " -2.55730261e-02  1.19208663e-01  2.34612143e-01  2.39008969e-01\n",
            "  4.39065300e-02 -4.84712953e-03  1.61454696e-02  1.53217060e-02\n",
            "  3.81971127e-02 -4.70858696e-02  7.79878495e-01  1.71787307e-01\n",
            " -1.15969242e-02  5.93281827e-02 -9.10782779e-03 -9.94107038e-02\n",
            "  1.41874101e-01 -3.14825480e-02  2.90462065e-02 -2.35579763e-02\n",
            "  2.79001958e-02  3.10576396e-03 -6.55583734e-03  4.39012371e-02\n",
            "  1.01707827e-03 -1.68494684e-02 -5.05693722e-03  3.28995158e+00\n",
            " -2.75731615e-02 -8.01399348e-04 -1.19453830e-01  3.66776128e-02\n",
            "  2.20619672e-02  1.86964777e-02 -2.09280807e-01 -2.21941705e-01\n",
            "  3.19830113e-02  4.18100687e-01 -3.63323539e-01 -2.77286900e-01\n",
            "  2.99774239e-01 -1.26612932e-02]\n"
          ]
        }
      ],
      "source": [
        "print(\"loss is \", loss)\n",
        "print(\"w is \", w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tVYvOh61yaI"
      },
      "source": [
        "### Trying to predict x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T19:57:29.290241071Z",
          "start_time": "2023-10-27T19:57:29.287028223Z"
        },
        "id": "7tO-fpfn1yaI"
      },
      "outputs": [],
      "source": [
        "def prediction_labels(weights, data):\n",
        "    \"\"\"Generates class predictions given weights, and a test data matrix.\"\"\"\n",
        "    y_pred = sigmoid(np.dot(data, weights))\n",
        "    # display(y_pred)\n",
        "    y_pred[np.where(y_pred >= 0.5)] = 1\n",
        "    y_pred[np.where(y_pred < 0.5)] = 0\n",
        "    return y_pred\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "temp (328135,)\n"
          ]
        }
      ],
      "source": [
        "y_pred = prediction_labels(w, x_train_std)\n",
        "temp = y_pred[y_pred != -1]\n",
        "print(\"temp\", temp.shape)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T19:57:31.240908682Z",
          "start_time": "2023-10-27T19:57:31.216234202Z"
        },
        "id": "076JSyQW1yaI",
        "outputId": "f0384d6f-92c4-411f-83e0-ba717a52f803"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "y_train_01 =  np.where(y_train== -1,0,  1) # doesn't change anything ofc"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T19:57:53.347164526Z",
          "start_time": "2023-10-27T19:57:53.335290169Z"
        },
        "id": "o9_MQrtg1yaI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T19:58:10.480692069Z",
          "start_time": "2023-10-27T19:58:10.437001412Z"
        },
        "id": "4PCigyW_1yaJ",
        "outputId": "33a40e69-b78f-4bf4-b105-e56721d16dc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy 0.9133314032334253\n"
          ]
        }
      ],
      "source": [
        "accuracy = (y_pred == y_train).sum() / len(y_train)\n",
        "print(\"accuracy\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T20:08:27.788890479Z",
          "start_time": "2023-10-27T20:08:27.747984285Z"
        },
        "id": "Olus7nJE1yaJ",
        "outputId": "ff417f4f-dd74-4df5-fe57-23002187f83a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train_std (328135, 146) w shape (146,)\n"
          ]
        }
      ],
      "source": [
        "print(\"x_train_std\", x_train_std.shape, \"w shape\", w.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "array([0., 0., 0., ..., 0., 0., 0.])"
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# predict on x_test\n",
        "y_pred_test = prediction_labels(w, x_test_std)\n",
        "y_pred_test"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T20:09:44.876875835Z",
          "start_time": "2023-10-27T20:09:44.830460281Z"
        },
        "id": "1dHzPt1-1yaJ",
        "outputId": "8b6db38a-198a-41c6-ee6e-a10776f86741"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "109379\n"
          ]
        }
      ],
      "source": [
        "y_pred_test=  np.where(y_pred_test== 0, -1, 1)\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T20:10:40.965033107Z",
          "start_time": "2023-10-27T20:10:40.785545283Z"
        },
        "id": "g4jV6i111yaJ",
        "outputId": "264b5b12-9646-4b4b-e17a-184bde9f9d57"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def accuracy(y_pred, y_train):\n",
        "    return (y_pred == y_train).sum() / len(y_train)\n",
        "def precision(y_pred, y_train):\n",
        "    TP = np.sum((y_train==1) & (y_pred==1))\n",
        "    FP = np.sum((y_train==0) & (y_pred==1))\n",
        "    return TP/(TP+FP)\n",
        "def recall(y_pred, y_train):\n",
        "    recall = np.sum((y_train==1) & (y_pred==1)) / np.sum(y_train==1)\n",
        "    return recall\n",
        "def f_score (y_pred, y_train):\n",
        "    return 2*precision(y_pred, y_train)*recall(y_pred, y_train) / (precision(y_pred, y_train) + recall(y_pred, y_train))\n",
        "\n",
        "print(\"accuracy\", accuracy(y_pred, y_train))\n",
        "print(\"precision\", precision(y_pred, y_train))\n",
        "print(\"recall\", recall(y_pred, y_train))\n",
        "print(\"f_score\", f_score(y_pred, y_train))\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T20:09:52.757866143Z",
          "start_time": "2023-10-27T20:09:52.743103573Z"
        },
        "id": "aD3hkf8P1yaK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'compute_confusion_matrix_elements' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_8643/1189945210.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_confusion_matrix_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"F1 Score: {f1_score(TP, FP, FN)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TP: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FP: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TN: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FN: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'compute_confusion_matrix_elements' is not defined"
          ]
        }
      ],
      "source": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T21:18:06.806341813Z",
          "start_time": "2023-10-27T21:18:06.773760012Z"
        },
        "id": "T_sPbrAU1yaK",
        "outputId": "a6047a19-36c3-45a4-c49f-314e2b07e7c1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzyDQAAd1yaK"
      },
      "source": [
        "## Logistic regression with regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T16:50:08.250080582Z",
          "start_time": "2023-10-27T16:50:08.205100158Z"
        },
        "id": "3V76ctNM1yaK"
      },
      "outputs": [],
      "source": [
        "def logistic_gradient(y, tx, w):\n",
        "    return  tx.T.dot(sigmoid(tx.dot(w)) - y)/ len(y)\n",
        "def compute_gradient_logistic_loss_regularized(y, tx, w, lambda_):\n",
        "    \"\"\"Compute the gradient of the regularized logistic regression \"\"\"\n",
        "    grad = logistic_gradient(y, tx, w) + lambda_ * w\n",
        "    return grad\n",
        "\n",
        "def regularized_log_reg_sgd(y, tx, initial_w, max_iters, gamma,  lambda_ ):\n",
        "    \"\"\"Regularized logistic regression using stochastic gradient descent.\"\"\"\n",
        "    w = initial_w\n",
        "    prev_loss = float('inf')\n",
        "\n",
        "    for n_iter in range(max_iters):\n",
        "\t\t# Each iteration corresponds to one epoch (num_batches=len(y)) and each batch has size 1\n",
        "        for batch_y, batch_x in batch_iter(y, tx, 1, num_batches=len(y)):\n",
        "\t\t\t# Computing the gradient of the logistic loss with respect to w\n",
        "            gradient = compute_gradient_logistic_loss_regularized(batch_y, batch_x, w, lambda_)\n",
        "\t\t\t# Updating w\n",
        "            w -= gamma * gradient\n",
        "\n",
        "\n",
        "        loss = logistic_loss(y, tx, w) + (lambda_ / 2) * np.squeeze(w.T @ w)\n",
        "        if prev_loss <= loss:\n",
        "            gamma *= 0.1  # adapt step size\n",
        "        prev_loss = loss\n",
        "\n",
        "    return w, loss\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# model paramaters (not optimized yet)\n",
        "initial_w = np.zeros(x_train_std.shape[1], dtype=np.float64)\n",
        "max_iters = 100\n",
        "gamma = 0.01\n",
        "lambda_ = 0.0001\n",
        "\n",
        "w, loss = regularized_log_reg_sgd(y_train, x_train_std, initial_w, max_iters, gamma, lambda_)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T16:56:23.790403704Z",
          "start_time": "2023-10-27T16:50:11.110180097Z"
        },
        "id": "rRNeEP2J1yaK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "y_pred_reg = prediction_labels(w, x_train_std)\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T17:00:07.842713100Z",
          "start_time": "2023-10-27T17:00:07.790268935Z"
        },
        "id": "j0l_xjrH1yaP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "shapes (109379,201) and (202,) not aligned: 201 (dim 1) != 202 (dim 0)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_34530/2573781482.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_34530/2866957613.py\u001b[0m in \u001b[0;36mprediction_labels\u001b[0;34m(weights, data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprediction_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Generates class predictions given weights, and a test data matrix.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# display(y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (109379,201) and (202,) not aligned: 201 (dim 1) != 202 (dim 0)"
          ]
        }
      ],
      "source": [
        "y_pred_test = prediction_labels(w, x_test)\n",
        "y_pred_test.shape"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T17:15:16.299441537Z",
          "start_time": "2023-10-27T17:15:16.282698488Z"
        },
        "id": "hQtFIQPl1yaP",
        "outputId": "ab0f7a73-ac30-47fd-c03e-063840be738b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy 0.9134228290185442\n"
          ]
        }
      ],
      "source": [
        "accuracy = (y_pred_reg == y_train).sum() / len(y_train)\n",
        "print(\"accuracy\", accuracy)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T17:00:13.478684587Z",
          "start_time": "2023-10-27T17:00:13.470131956Z"
        },
        "id": "kiBANdiP1yaP",
        "outputId": "970ccf78-9ad4-4df4-99be-bf16dc1ed80d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "109379\n"
          ]
        },
        {
          "data": {
            "text/plain": "-105523"
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# convert 0,1 labels to 1 and -1\n",
        "y_submit =  np.where(y_pred_test== 0, -1, 1)\n",
        "print(len(y_submit))\n",
        "y_submit.sum()\n",
        "create_csv_submission(test_ids, y_submit, \"submition0\")\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T17:05:59.435446943Z",
          "start_time": "2023-10-27T17:05:59.429089431Z"
        },
        "id": "VKgA5d1o1yaP",
        "outputId": "23832948-5cdc-4061-d8e2-b586b794339f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "create_csv_submission(test_ids, y_submit, \"submition0\")\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T17:18:28.322762179Z",
          "start_time": "2023-10-27T17:18:28.100851008Z"
        },
        "id": "pI0jHy_41yaP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "def cross_validation(y, x, k_indices, k, method, **args):\n",
        "    \"\"\"\n",
        "    Completes k-fold cross-validation using the regression method\n",
        "    \"\"\"\n",
        "    # Get k'th subgroup in test, others in train\n",
        "    tr_indices_set = np.delete(k_indices, k, 0).flatten()\n",
        "    x_tr = x[tr_indices_set]\n",
        "    y_tr = y[tr_indices_set]\n",
        "\n",
        "    te_indices = k_indices[k]\n",
        "    x_te = x[te_indices]\n",
        "    y_te = y[te_indices]\n",
        "\n",
        "    # Apply the regression method\n",
        "    w, loss = method(y=y_train, tx=x_train_std, **args)\n",
        "\n",
        "    # Predict outputs with the w\n",
        "    y_pred = prediction_labels(w, x_te)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    #accurancy = compute_accuracy(y_te, predictions)\n",
        "\n",
        "    #return accuracy"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-27T14:00:30.519601520Z",
          "start_time": "2023-10-27T14:00:30.478507656Z"
        },
        "id": "54pjquEG1yaQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "VpH0cOO-1yaQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def build_k_indices(y, k_fold, seed):\n",
        "    \"\"\"build k indices for k-fold.\n",
        "\n",
        "    Args:\n",
        "        y:      shape=(N,)\n",
        "        k_fold: K in K-fold, i.e. the fold num\n",
        "        seed:   the random seed\n",
        "\n",
        "    Returns:\n",
        "        A 2D array of shape=(k_fold, N/k_fold) that indicates the data indices for each fold\n",
        "    \"\"\"\n",
        "    num_row = y.shape[0]\n",
        "    interval = int(num_row / k_fold)\n",
        "    np.random.seed(seed)\n",
        "    indices = np.random.permutation(num_row)\n",
        "    k_indices = [indices[k * interval : (k + 1) * interval] for k in range(k_fold)]\n",
        "    return np.array(k_indices)\n",
        "\n",
        "# feel free to remove the f1 score thing and change parameters\n",
        "def get_best_parameters(y, tx, intitial_w, max_iters, gamma, lambdas, k_fold):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "        y:\n",
        "        tx:\n",
        "        intitial_w:\n",
        "        max_iters:\n",
        "        gamma:\n",
        "        lambdas:\n",
        "        k_fold:\n",
        "\n",
        "    Returns: best lambda parameter\n",
        "\n",
        "    \"\"\"\n",
        "    # split data in k fold\n",
        "    k_indices = build_k_indices(y, k_fold, seed)\n",
        "\n",
        "\n",
        "    rmse_tr = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for lambda_ in lambdas:\n",
        "        rmsetr_tmp = []\n",
        "        f1_tmp = []\n",
        "        for k in range(k_fold):\n",
        "            # make cross validation return weight\n",
        "            w, loss = cross_validation(y,tx, initial_w, max_iters, gamma)\n",
        "            rmsetr_tmp.append(loss)\n",
        "            y_pred = prediction_labels(w, tx)\n",
        "            f1_tmp.append(f1_score(y_pred, y))\n",
        "\n",
        "        rmse_tr.append(np.mean(rmsetr_tmp))\n",
        "        f1_scores.append(np.mean(f1_tmp))\n",
        "    best_lambda, best_rmse, best_f1  = lambdas[np.argmin(rmse_tr)], np.min(rmse_tr), np.min(f1_scores)\n",
        "    print( \"The best rmse of %.3f is obtained for a lambda of %.5f.\"%(best_rmse, best_lambda))\n",
        "    print(\"The best f1-score of %.3f is obtained for a lambda of %.5f.\"%(best_f1, best_lambda))\n",
        "    return best_lambda\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D5Mq1Gk11yaQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "N7T2s2fO1yaQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "Et6N0dHv1yaQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "yhdynEY71yaQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "VHg4-SHR1yaQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "f-vlgw5p1yaR"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}