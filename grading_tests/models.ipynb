{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T21:27:33.950806049Z",
     "start_time": "2023-10-27T21:27:33.622980970Z"
    }
   },
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-27T21:27:39.895316925Z"
    }
   },
   "outputs": [],
   "source": [
    "## Use pickle instead of csv, much faster, please comment out below \n",
    "data_path = '../data/dataset_to_release'\n",
    "x_train_preclean, x_test_preclean, y_train, train_ids, test_ids = load_csv_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting an idea of the data \n",
    "Find really bad columns and drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(\"X train\", x_train_preclean.shape)\n",
    "print(\"X test\", x_test_preclean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T21:27:30.914555608Z",
     "start_time": "2023-10-27T21:27:30.868179191Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_8643/2371916613.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mpercentage_filled\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_along_axis\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpercentageFilled\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_train_preclean\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "## Find how many values are completely empty in column\n",
    "def percentageFilled(data):\n",
    "    return 1 - np.isnan(data).sum() / len(data)\n",
    "\n",
    "\n",
    "percentage_filled = np.apply_along_axis(percentageFilled, 0, x_train_preclean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T16:46:35.485656145Z",
     "start_time": "2023-10-27T16:46:33.133801294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_indicies [  0   1   2   3   4   5   6   7   8  10  13  15  16  17  20  21  23  24\n",
      "  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  42  43\n",
      "  44  45  46  47  48  50  51  52  53  54  56  57  58  59  60  61  62  63\n",
      "  65  66  67  68  69  70  71  72  73  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 118 136 198 199 216 217 218 219 220 221 222 223 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263\n",
      " 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281\n",
      " 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299\n",
      " 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317\n",
      " 318 319 320]\n",
      "len indices 201\n"
     ]
    }
   ],
   "source": [
    "## Process data \n",
    "## 1. drop the columns with more than 80% missing values\n",
    "def threshold_col_filter(data, threshold):\n",
    "    \"\"\" \n",
    "    filter out data where the column has less than threshold percentage of data\n",
    "    returns: \n",
    "        indicies of columns to keep\n",
    "    \"\"\"\n",
    "    percentage_filled = np.apply_along_axis(percentageFilled, 0, data)\n",
    "    # keep_indicies = np.argwhere(percentage_filled > threshold).flatten()\n",
    "    return percentage_filled > threshold\n",
    "\n",
    "\n",
    "def non_constant_filter(data):\n",
    "    return np.logical_not(np.logical_or(np.isnan(np.nanstd(data, 0)), np.nanstd(data, 0) == 0))\n",
    "\n",
    "# TODO uncorrelation?\n",
    "\n",
    "# TODO correlation w\n",
    "\n",
    "keep_indicies = np.argwhere(np.logical_and(\n",
    "    threshold_col_filter(x_train_preclean, 0.2), \n",
    "    non_constant_filter(x_train_preclean)\n",
    "    )\n",
    ").flatten()\n",
    "\n",
    "print(\"keep_indicies\", keep_indicies)\n",
    "print(\"len indices\", len(keep_indicies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data cleaning \n",
    "\n",
    "1. remove columns where 80% of the values are missing\n",
    "2. replace the missing values of X with the mean of the column\n",
    "3. standardize the data\n",
    "4. add column of 1 at the beginning  \n",
    "\n",
    "# **Make sure you do the same for x_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T16:47:19.162302956Z",
     "start_time": "2023-10-27T16:47:15.441926117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_indicies [  0   1   2   3   4   5   6   7   8  10  13  15  16  17  20  21  23  24\n",
      "  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  42  43\n",
      "  44  45  46  47  48  50  51  52  53  54  56  57  58  59  60  61  62  63\n",
      "  65  66  67  68  69  70  71  72  73  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 118 136 198 199 216 217 218 219 220 221 222 223 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263\n",
      " 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281\n",
      " 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299\n",
      " 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317\n",
      " 318 319 320]\n",
      "X train (328135, 201)\n",
      "X test (109379, 201)\n"
     ]
    }
   ],
   "source": [
    "def is_categorical_feature(xn, threshold=0.05):\n",
    "    return len(set(xn)) / len(xn) < threshold\n",
    "\n",
    "def standardize(x):\n",
    "    \"\"\"Standardize the original data set.\"\"\"\n",
    "    return np.nan_to_num((x - np.nanmean(x, axis=0)) / np.nanstd(x, axis=0))\n",
    "\n",
    "def one_hot_encode(xn):\n",
    "    pass\n",
    "     # TODO\n",
    "\n",
    "def percentageFilled(data):\n",
    "    return 1 - np.isnan(data).sum() / len(data)\n",
    "\n",
    "def threshold_col_filter(data, threshold):\n",
    "    percentage_filled = np.apply_along_axis(percentageFilled, 0, data)\n",
    "    # keep_indicies = np.argwhere(percentage_filled > threshold).flatten()\n",
    "    return percentage_filled > threshold\n",
    "\n",
    "def non_constant_filter(data):\n",
    "    return np.logical_not(np.logical_or(np.isnan(np.nanstd(data, 0)), np.nanstd(data, 0) == 0))\n",
    "\n",
    "def almost_constant_filter(data, threshold=0.01):\n",
    "    std_devs = np.nanstd(data, axis=0)\n",
    "    mask = std_devs > threshold\n",
    "    return mask\n",
    "\n",
    "\n",
    "keep_indicies = np.argwhere(np.logical_and(\n",
    "    threshold_col_filter(x_train_preclean, 0.2),\n",
    "    non_constant_filter(x_train_preclean),\n",
    "    almost_constant_filter(x_train_preclean, 0.01)\n",
    "    )\n",
    ").flatten()\n",
    "print(\"keep_indicies\", keep_indicies)\n",
    "\n",
    "def filter_columns_by_indicies(data, keep_indicies):\n",
    "    \"\"\"\n",
    "    used to process test data\n",
    "    only keep the columns that are in the indicies\n",
    "    \"\"\"\n",
    "    return data[:, keep_indicies]\n",
    "\n",
    "\n",
    "x_train = filter_columns_by_indicies(x_train_preclean, keep_indicies)\n",
    "print(\"X train\", x_train.shape)\n",
    "\n",
    "x_test = filter_columns_by_indicies(x_test_preclean, keep_indicies)\n",
    "print(\"X test\", x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T20:14:23.927708029Z",
     "start_time": "2023-10-27T20:14:23.921579018Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_43080/2105045438.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m \u001B[0mx_train_std\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprocess_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0mx_test_std\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprocess_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'x_test_std'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_test_std\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "## 2. Replace the missing values with the mean of the column, add columns \n",
    "def standardize(x):\n",
    "    \"\"\"Standardize the original data set.\"\"\"\n",
    "    return np.nan_to_num((x - np.nanmean(x, axis=0)) / np.nanstd(x, axis=0))\n",
    "\n",
    "def standardize_median(x):\n",
    "    return np.nan_to_num(np.abs(x - np.nanmedian(x, axis=0)) / np.nanstd(x, axis=0))\n",
    "\n",
    "\n",
    "def process_data(x):\n",
    "    x = standardize(x)\n",
    "    x = np.c_[np.ones(len(x)), x]  # add the column of ones\n",
    "    return x\n",
    "\n",
    "x_train_std = process_data(x_train)\n",
    "x_test_std = process_data(x_test)\n",
    "print('x_test_std', x_test_std.shape)\n",
    "print('x_train_std', x_train_std.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression *without* regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logisitc regression different than the one in implementations.py. uses stochastic gradient descent. Slight modifications to sigmoid and loss to not make an overflow."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    t = np.clip(t, -709, 709)  # Clip to avoid overflow. exp(709) is close to the maximum representable float64\n",
    "    return np.where(t < 0, np.exp(t)/(1.0 +np.exp(t)) , 1.0 / (1.0 + np.exp(-t)))\n",
    "def logistic_loss(y, tx, w):\n",
    "    epsilon = 0.000000001\n",
    "    y_hat = sigmoid(tx.dot(w))\n",
    "    y_hat = np.clip(y_hat, epsilon, 1-epsilon)\n",
    "    loss = - np.average(y*np.log(y_hat) + (1-y)*np.log(1-y_hat))\n",
    "    return loss\n",
    "\n",
    "def logistic_gradient(y, tx, w):\n",
    "    return  tx.T.dot(sigmoid(tx.dot(w)) - y)/ len(y)\n",
    "\n",
    "    \n",
    "def logistic_regression_step(y, tx, initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    prev_loss = float('inf')\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "       for batch_y, batch_x in batch_iter(y, tx, 1, num_batches=len(tx)):\n",
    "          gradient = logistic_gradient(batch_y, batch_x, w)\n",
    "          w = w - gamma * gradient\n",
    "\n",
    "       loss = logistic_loss(y, tx, w)\n",
    "       if prev_loss <= loss:\n",
    "          gamma *= 0.1        # control of the step size\n",
    "       prev_loss = loss\n",
    "       #print(\"SGD iter. {bi}/{ti}: loss={l}, w={}\".format(   bi=n_iter, ti=max_iters - 1, l=loss, w=w))\n",
    "        \n",
    "    return w, loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T19:43:45.128570767Z",
     "start_time": "2023-10-27T19:43:45.124241051Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T19:43:53.027172684Z",
     "start_time": "2023-10-27T19:43:53.017581669Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_w = np.zeros(x_train_std.shape[1], dtype=np.float64) # float64 can be faster and more stable to overflow issues appearantly\n",
    "max_iters = 100\n",
    "gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T19:56:30.673559521Z",
     "start_time": "2023-10-27T19:43:54.973447960Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "w, loss = logistic_regression_step(y_train, x_train_std, initial_w, max_iters, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T19:57:18.280795826Z",
     "start_time": "2023-10-27T19:57:18.236452608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is  0.22924340476877145\n",
      "w is  [-3.27714283e+00  5.97358740e-03  1.56328367e-02  1.09390716e-02\n",
      " -1.01284227e-02  2.24112448e-02 -2.30569832e-02  0.00000000e+00\n",
      "  0.00000000e+00 -5.13949071e-01  4.10297682e-02  0.00000000e+00\n",
      " -1.70812189e-01  0.00000000e+00 -2.41542597e-02  6.15125785e-03\n",
      "  1.14175303e-02  5.94134381e-01 -7.39418409e-02 -4.76007255e-03\n",
      " -2.10028480e-02 -2.76006599e-03  3.63636231e-02 -3.96158969e-02\n",
      "  1.01179566e-02 -2.01473154e-01 -8.30796054e-02 -2.80547196e-01\n",
      " -2.52487516e-01 -2.50054271e-01 -1.34269832e-01 -1.64759702e-02\n",
      " -2.36521036e-02  1.09567745e-02 -5.90979124e-02 -3.19943082e-02\n",
      " -2.01536670e-02 -5.30932673e-02 -9.71013368e-02 -5.02039207e-02\n",
      " -1.42322480e-02  3.40141487e-02 -1.84255016e-02  2.26267116e-03\n",
      " -1.14936679e-01  1.35321426e-01 -5.64887148e-03 -2.71442679e-02\n",
      "  3.23787539e-02 -4.54569961e-02 -1.57900825e-02 -3.70927422e-02\n",
      " -3.69578301e-02 -2.20893986e-02 -4.73067695e-03 -3.25744003e-02\n",
      "  1.81063129e-02  3.91958186e-03 -1.08893002e-01 -1.37895984e-01\n",
      " -6.10165439e-03  1.23568858e-02  8.98930094e-02  5.70066061e-03\n",
      "  7.70949141e-02  5.04885317e-03 -4.71545284e-03  7.93441572e-03\n",
      "  1.36270526e-02  3.86953787e-02 -5.08600085e-03 -1.12480116e-02\n",
      "  1.57498712e-02  8.47206091e-03  1.43550487e-02  6.21139023e-03\n",
      "  2.03572131e-02  1.68089160e-02  2.63680063e-02 -3.47947123e-03\n",
      " -1.45595602e-02 -3.71198978e-03  6.31685310e-03  1.15290144e-02\n",
      "  5.63159865e-02 -1.15400444e-02 -3.61276229e-03 -1.05754295e-02\n",
      " -1.18128665e-01  1.19144688e-02 -1.63894586e-02 -3.50470946e-02\n",
      " -2.12055140e-01  5.63101387e-02  7.81421935e-04 -4.78001975e-02\n",
      "  4.75759118e-02 -2.14486327e-02  3.05631498e-02 -4.90956626e-03\n",
      " -3.46966842e-02 -6.39156550e-03  6.61200940e-03 -1.12742803e-01\n",
      " -2.55730261e-02  1.19208663e-01  2.34612143e-01  2.39008969e-01\n",
      "  4.39065300e-02 -4.84712953e-03  1.61454696e-02  1.53217060e-02\n",
      "  3.81971127e-02 -4.70858696e-02  7.79878495e-01  1.71787307e-01\n",
      " -1.15969242e-02  5.93281827e-02 -9.10782779e-03 -9.94107038e-02\n",
      "  1.41874101e-01 -3.14825480e-02  2.90462065e-02 -2.35579763e-02\n",
      "  2.79001958e-02  3.10576396e-03 -6.55583734e-03  4.39012371e-02\n",
      "  1.01707827e-03 -1.68494684e-02 -5.05693722e-03  3.28995158e+00\n",
      " -2.75731615e-02 -8.01399348e-04 -1.19453830e-01  3.66776128e-02\n",
      "  2.20619672e-02  1.86964777e-02 -2.09280807e-01 -2.21941705e-01\n",
      "  3.19830113e-02  4.18100687e-01 -3.63323539e-01 -2.77286900e-01\n",
      "  2.99774239e-01 -1.26612932e-02]\n"
     ]
    }
   ],
   "source": [
    "print(\"loss is \", loss)\n",
    "print(\"w is \", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to predict x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T19:57:29.290241071Z",
     "start_time": "2023-10-27T19:57:29.287028223Z"
    }
   },
   "outputs": [],
   "source": [
    "def prediction_labels(weights, data): \n",
    "    \"\"\"Generates class predictions given weights, and a test data matrix.\"\"\"\n",
    "    y_pred = sigmoid(np.dot(data, weights))\n",
    "    # display(y_pred)\n",
    "    y_pred[np.where(y_pred >= 0.5)] = 1\n",
    "    y_pred[np.where(y_pred < 0.5)] = 0\n",
    "    return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp (328135,)\n"
     ]
    }
   ],
   "source": [
    "y_pred = prediction_labels(w, x_train_std)\n",
    "temp = y_pred[y_pred != -1]\n",
    "print(\"temp\", temp.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T19:57:31.240908682Z",
     "start_time": "2023-10-27T19:57:31.216234202Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "y_train_01 =  np.where(y_train== -1,0,  1) # doesn't change anything ofc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T19:57:53.347164526Z",
     "start_time": "2023-10-27T19:57:53.335290169Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T19:58:10.480692069Z",
     "start_time": "2023-10-27T19:58:10.437001412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9133314032334253\n"
     ]
    }
   ],
   "source": [
    "accuracy = (y_pred == y_train).sum() / len(y_train)\n",
    "print(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T20:08:27.788890479Z",
     "start_time": "2023-10-27T20:08:27.747984285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_std (328135, 146) w shape (146,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train_std\", x_train_std.shape, \"w shape\", w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., ..., 0., 0., 0.])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on x_test\n",
    "y_pred_test = prediction_labels(w, x_test_std)\n",
    "y_pred_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T20:09:44.876875835Z",
     "start_time": "2023-10-27T20:09:44.830460281Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109379\n"
     ]
    }
   ],
   "source": [
    "y_pred_test=  np.where(y_pred_test== 0, -1, 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T20:10:40.965033107Z",
     "start_time": "2023-10-27T20:10:40.785545283Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def compute_confusion_matrix_elements(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred), \"Length of y_true and y_pred must be the same\"\n",
    "\n",
    "    TP = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    FP = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    TN = np.sum((y_pred == 0) & (y_true == 0))\n",
    "    FN = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    \n",
    "    return TP, FP, TN, FN\n",
    "\n",
    "def f1_score(TP, FP, FN):\n",
    "    if TP + FP == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = TP / (TP + FP)\n",
    "    \n",
    "    if TP + FN == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = TP / (TP + FN)\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * (precision * recall) / (precision + recall)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T20:09:52.757866143Z",
     "start_time": "2023-10-27T20:09:52.743103573Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_confusion_matrix_elements' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_8643/1189945210.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mTP\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mFP\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTN\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mFN\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_confusion_matrix_elements\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"F1 Score: {f1_score(TP, FP, FN)}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'TP: '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTP\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'FP: '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mFP\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'TN: '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTP\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'FN: '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mFP\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'compute_confusion_matrix_elements' is not defined"
     ]
    }
   ],
   "source": [
    "TP, FP, TN, FN = compute_confusion_matrix_elements(y_train, y_pred)\n",
    "print(f\"F1 Score: {f1_score(TP, FP, FN)}\")\n",
    "print('TP: ', TP, 'FP: ', FP)\n",
    "print('TN: ', TP, 'FN: ', FP)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T21:18:06.806341813Z",
     "start_time": "2023-10-27T21:18:06.773760012Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T16:50:08.250080582Z",
     "start_time": "2023-10-27T16:50:08.205100158Z"
    }
   },
   "outputs": [],
   "source": [
    "def logistic_gradient(y, tx, w):\n",
    "    return  tx.T.dot(sigmoid(tx.dot(w)) - y)/ len(y)\n",
    "def compute_gradient_logistic_loss_regularized(y, tx, w, lambda_):\n",
    "    \"\"\"Compute the gradient of the regularized logistic regression \"\"\"\n",
    "    grad = logistic_gradient(y, tx, w) + lambda_ * w\n",
    "    return grad\n",
    "\n",
    "def regularized_log_reg_sgd(y, tx, initial_w, max_iters, gamma,  lambda_ ):\n",
    "    \"\"\"Regularized logistic regression using stochastic gradient descent.\"\"\"\n",
    "    w = initial_w\n",
    "    prev_loss = float('inf')\n",
    "    \n",
    "    for n_iter in range(max_iters):\n",
    "\t\t# Each iteration corresponds to one epoch (num_batches=len(y)) and each batch has size 1\n",
    "        for batch_y, batch_x in batch_iter(y, tx, 1, num_batches=len(y)):\n",
    "\t\t\t# Computing the gradient of the logistic loss with respect to w\n",
    "            gradient = compute_gradient_logistic_loss_regularized(batch_y, batch_x, w, lambda_)\n",
    "\t\t\t# Updating w\n",
    "            w -= gamma * gradient\n",
    "        \n",
    "\t\t\n",
    "        loss = logistic_loss(y, tx, w) + (lambda_ / 2) * np.squeeze(w.T @ w)\n",
    "        if prev_loss <= loss:\n",
    "            gamma *= 0.1  # adapt step size\n",
    "        prev_loss = loss\n",
    "\n",
    "    return w, loss\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# model paramaters (not optimized yet)\n",
    "initial_w = np.zeros(x_train_std.shape[1], dtype=np.float64)\n",
    "max_iters = 100\n",
    "gamma = 0.01\n",
    "lambda_ = 0.0001\n",
    "\n",
    "w, loss = regularized_log_reg_sgd(y_train, x_train_std, initial_w, max_iters, gamma, lambda_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T16:56:23.790403704Z",
     "start_time": "2023-10-27T16:50:11.110180097Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "y_pred_reg = prediction_labels(w, x_train_std)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T17:00:07.842713100Z",
     "start_time": "2023-10-27T17:00:07.790268935Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (109379,201) and (202,) not aligned: 201 (dim 1) != 202 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_34530/2573781482.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0my_pred_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprediction_labels\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0my_pred_test\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_34530/2866957613.py\u001B[0m in \u001B[0;36mprediction_labels\u001B[0;34m(weights, data)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mprediction_labels\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweights\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0;34m\"\"\"Generates class predictions given weights, and a test data matrix.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msigmoid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweights\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0;31m# display(y_pred)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0my_pred\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwhere\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_pred\u001B[0m \u001B[0;34m>=\u001B[0m \u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/core/overrides.py\u001B[0m in \u001B[0;36mdot\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: shapes (109379,201) and (202,) not aligned: 201 (dim 1) != 202 (dim 0)"
     ]
    }
   ],
   "source": [
    "y_pred_test = prediction_labels(w, x_test)\n",
    "y_pred_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T17:15:16.299441537Z",
     "start_time": "2023-10-27T17:15:16.282698488Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9134228290185442\n"
     ]
    }
   ],
   "source": [
    "accuracy = (y_pred_reg == y_train).sum() / len(y_train)\n",
    "print(\"accuracy\", accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T17:00:13.478684587Z",
     "start_time": "2023-10-27T17:00:13.470131956Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109379\n"
     ]
    },
    {
     "data": {
      "text/plain": "-105523"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert 0,1 labels to 1 and -1\n",
    "y_submit =  np.where(y_pred_test== 0, -1, 1)\n",
    "print(len(y_submit))\n",
    "y_submit.sum()\n",
    "create_csv_submission(test_ids, y_submit, \"submition0\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T17:05:59.435446943Z",
     "start_time": "2023-10-27T17:05:59.429089431Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids, y_submit, \"submition0\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T17:18:28.322762179Z",
     "start_time": "2023-10-27T17:18:28.100851008Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "\n",
    "def cross_validation(y, x, k_indices, k, method, **args):\n",
    "    \"\"\"\n",
    "    Completes k-fold cross-validation using the regression method\n",
    "    \"\"\"\n",
    "    # Get k'th subgroup in test, others in train\n",
    "    tr_indices_set = np.delete(k_indices, k, 0).flatten()\n",
    "    x_tr = x[tr_indices_set]\n",
    "    y_tr = y[tr_indices_set] \n",
    "    \n",
    "    te_indices = k_indices[k]\n",
    "    x_te = x[te_indices]\n",
    "    y_te = y[te_indices]\n",
    "\n",
    "    # Apply the regression method\n",
    "    w, loss = method(y=y_train, tx=x_train_std, **args)\n",
    "\n",
    "    # Predict outputs with the w \n",
    "    y_pred = prediction_labels(w, x_te)\n",
    "\n",
    "    # Calculate accurancy\n",
    "    #accurancy = compute_accuracy(y_te, predictions)\n",
    "\n",
    "    #return accurancy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T14:00:30.519601520Z",
     "start_time": "2023-10-27T14:00:30.478507656Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
