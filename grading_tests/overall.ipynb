{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T13:53:39.958806032Z",
     "start_time": "2023-10-26T13:53:38.828203084Z"
    }
   },
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from implementations import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/imd/docs/univ/epfl/courses/ml/ML_project1/grading_tests'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T13:53:39.955737596Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "data_path = '../data/dataset/dataset_to_release'\n",
    "x_train_preclean, x_test_preclean, y_train, train_ids, test_ids = load_csv_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting an idea of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(\"X train\", x_train_preclean.shape)\n",
    "print(\"X test\", x_test_preclean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## Find how many values are completely empty in column\n",
    "def percentageFilled(data):\n",
    "    return 1 - np.isnan(data).sum() / len(data)\n",
    "\n",
    "percentage_filled = np.apply_along_axis(percentageFilled, 0, x_train_preclean)\n",
    "\n",
    "plt.hist(percentage_filled, bins=20)\n",
    "plt.title(\"Percentage of filled values per column\")\n",
    "plt.xlabel(\"Percentage\")\n",
    "plt.ylabel(\"# of columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## Process data \n",
    "## 1. drop the columns with more than 80% missing values\n",
    "def threshold_col_filter(data, threshold):\n",
    "    \"\"\" \n",
    "    filter out data where the column has less than threshold percentage of data\n",
    "    returns: \n",
    "        indicies of columns to keep\n",
    "    \"\"\"\n",
    "    percentage_filled = np.apply_along_axis(percentageFilled, 0, data)\n",
    "    # keep_indicies = np.argwhere(percentage_filled > threshold).flatten()\n",
    "    return percentage_filled > threshold\n",
    "\n",
    "\n",
    "def non_constant_filter(data):\n",
    "    \"\"\"\n",
    "    filter out where the values in the column are all the same\n",
    "    \"\"\"\n",
    "    return np.logical_not(np.logical_or(np.isnan(np.nanstd(data, 0)), np.nanstd(data, 0) == 0))\n",
    "\n",
    "# TODO uncorrelation?\n",
    "    \n",
    "\n",
    "# TODO correlation w\n",
    "## SEE LATER, done at a later stage, after these two steps  \n",
    "\n",
    "\n",
    "keep_indicies = np.argwhere(np.logical_and(\n",
    "    threshold_col_filter(x_train_preclean, 0.2), \n",
    "    non_constant_filter(x_train_preclean))\n",
    ").flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    \"\"\"Standardize the original data set.\"\"\"\n",
    "    std = np.nanstd(x, axis=0)\n",
    "    mean = np.nanmean(x, axis=0)\n",
    "    return np.nan_to_num((x - np.nanmean(x, axis=0)) / np.nanstd(x, axis=0)), mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def transform_train(feature):\n",
    "    m = dict()\n",
    "    for x in feature:\n",
    "        if x not in m:\n",
    "            m[x] = len(m)\n",
    "    f = np.vstack((np.eye(len(m)), np.zeros(len(m))))\n",
    "    u = f[np.vectorize(lambda key: m.get(key, len(m)))(feature)]\n",
    "    return u, m\n",
    "\n",
    "\n",
    "def transform_test(feature, m):\n",
    "    n_uniq = len(m)\n",
    "    f = np.vstack((np.eye(n_uniq), np.zeros(n_uniq)))\n",
    "    ind = np.array([m[k] if k in m else n_uniq for k in feature])\n",
    "    return f[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def process_train(data, cat_threshold = 10):\n",
    "    n, m = data.shape\n",
    "    filter = np.logical_and(threshold_col_filter(data, 0.2), non_constant_filter(data))\n",
    "    categorical_filter = np.apply_along_axis(lambda x: len(set(x)) < cat_threshold, 0, data)\n",
    "    cat_transform = dict()\n",
    "    num_transform = dict()\n",
    "    res = np.empty((n, 0))\n",
    "    for i in range(m):\n",
    "        if not filter[i]:\n",
    "            continue\n",
    "        if categorical_filter[i]:\n",
    "            encoded, mp = transform_train(data[:, i])\n",
    "            cat_transform[i] = mp\n",
    "            res = np.append(res, encoded, axis=1)\n",
    "        else:\n",
    "            x_num_std, mean, std = standardize(data[:, i])\n",
    "            x_num_std[abs(x_num_std) > 3] = 0\n",
    "            num_transform[i] = (mean, std)\n",
    "            res = np.append(res, x_num_std.reshape((n,1)), axis=1)\n",
    "    return res, filter, categorical_filter, num_transform, cat_transform\n",
    "\n",
    "\n",
    "def process_test(data, filter, categorical_filter, num_transform, cat_transform):\n",
    "    n, m = data.shape\n",
    "    res = np.empty((n, 0))\n",
    "    for i in range(m):\n",
    "        if not filter[i]:\n",
    "            continue\n",
    "        if categorical_filter[i]:\n",
    "            res = np.append(res, transform_test(data[:, i], cat_transform[i]), axis=1)\n",
    "        else:\n",
    "            mean, std = num_transform[i] # std shouldn't be 0\n",
    "            res = np.append(res, np.nan_to_num((data[:, i] - mean) / std).reshape((n,1)), axis=1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, feature_filter, categorical_filter, num_transform, cat_transform = process_train(x_train_preclean)\n",
    "\n",
    "x_test = process_test(x_test_preclean, feature_filter, categorical_filter, num_transform, cat_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"# x_train shape: {x_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def feature_correlation(x1, x2):\n",
    "#     return np.abs(np.corrcoef(x1, x2, rowvar=False))\n",
    "# \n",
    "# cr  =  feature_correlation(x_train_std, y_train)[-1, :-1]\n",
    "# plt.hist(cr, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Screen out features based on correlation\n",
    "# good_corre_indicies = np.argwhere(cr > 0.05).flatten()\n",
    "# print(\"good_corre_indicies\", good_corre_indicies)\n",
    "# x_train_corre = x_train_std[:, good_corre_indicies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression *without* regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "initial_w = np.zeros(x_train.shape[1], dtype=np.float128)\n",
    "max_iters = 100\n",
    "gamma = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "## Here the logistic regression is from implementations.py\n",
    "## \n",
    "w, loss = logistic_regression(y_train, x_train, initial_w, max_iters, gamma)\n",
    "print(\"loss is \", loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to predict x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def prediction_labels(weights, data):  ## isn't this for linear regression only ? Don't we need the sigmoid?\n",
    "    \"\"\"Generates class predictions given weights, and a test data matrix.\"\"\"\n",
    "    y_pred = sigmoid(np.dot(data, weights))\n",
    "    y_pred[np.where(y_pred >= 0.5)] = 1\n",
    "    y_pred[np.where(y_pred < 0.5)] = 0\n",
    "    return y_pred\n",
    "\n",
    "y_pred = prediction_labels(w, x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_train):\n",
    "    return (y_pred == y_train).sum() / len(y_train)\n",
    "def precision(y_pred, y_train):\n",
    "    TP = np.sum((y_train==1) & (y_pred==1))\n",
    "    FP = np.sum((y_train==0) & (y_pred==1))\n",
    "    return TP/(TP+FP)\n",
    "def recall(y_pred, y_train):\n",
    "    recall = np.sum((y_train==1) & (y_pred==1)) / np.sum(y_train==1)\n",
    "    return recall\n",
    "def f_score (y_pred, y_train):\n",
    "    return 2*precision(y_pred, y_train)*recall(y_pred, y_train) / (precision(y_pred, y_train) + recall(y_pred, y_train))\n",
    "\n",
    "print(\"accuracy\", accuracy(y_pred, y_train))\n",
    "print(\"precision\", precision(y_pred, y_train))\n",
    "print(\"recall\", recall(y_pred, y_train))\n",
    "print(\"f_score\", f_score(y_pred, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate trained data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "y_pred = prediction_labels(w, x_test)\n",
    "y_pred[y_pred == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids, y_pred, 'submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with regularization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
