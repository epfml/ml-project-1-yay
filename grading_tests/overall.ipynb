{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T13:53:39.958806032Z",
     "start_time": "2023-10-26T13:53:38.828203084Z"
    }
   },
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from implementations import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T13:53:39.955737596Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "data_path = '../data/dataset/dataset_to_release'\n",
    "x_train_preclean, x_test_preclean, y_train, train_ids, test_ids = load_csv_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting an idea of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(\"X train\", x_train_preclean.shape)\n",
    "print(\"X test\", x_test_preclean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## Find how many values are completely empty in column\n",
    "def percentageFilled(data):\n",
    "    return 1 - np.isnan(data).sum() / len(data)\n",
    "\n",
    "percentage_filled = np.apply_along_axis(percentageFilled, 0, x_train_preclean)\n",
    "\n",
    "plt.hist(percentage_filled, bins=20)\n",
    "plt.title(\"Percentage of filled values per column\")\n",
    "plt.xlabel(\"Percentage\")\n",
    "plt.ylabel(\"# of columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## Process data \n",
    "## 1. drop the columns with more than 80% missing values\n",
    "def threshold_col_filter(data, threshold):\n",
    "    \"\"\" \n",
    "    filter out data where the column has less than threshold percentage of data\n",
    "    returns: \n",
    "        indicies of columns to keep\n",
    "    \"\"\"\n",
    "    percentage_filled = np.apply_along_axis(percentageFilled, 0, data)\n",
    "    # keep_indicies = np.argwhere(percentage_filled > threshold).flatten()\n",
    "    return percentage_filled > threshold\n",
    "\n",
    "\n",
    "def non_constant_filter(data):\n",
    "    \"\"\"\n",
    "    filter out where the values in the column are all the same\n",
    "    \"\"\"\n",
    "    return np.logical_not(np.logical_or(np.isnan(np.nanstd(data, 0)), np.nanstd(data, 0) == 0))\n",
    "\n",
    "# TODO uncorrelation?\n",
    "    \n",
    "\n",
    "# TODO correlation w\n",
    "## SEE LATER, done at a later stage, after these two steps  \n",
    "\n",
    "\n",
    "keep_indicies = np.argwhere(np.logical_and(\n",
    "    threshold_col_filter(x_train_preclean, 0.2), \n",
    "    non_constant_filter(x_train_preclean)\n",
    "    )\n",
    ").flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def filter_columns_by_indicies(data, keep_indicies):\n",
    "    \"\"\"\n",
    "    used to process test data \n",
    "    only keep the columns that are in the indicies \n",
    "    \"\"\"\n",
    "    return data[:, keep_indicies]\n",
    "\n",
    "\n",
    "x_train = filter_columns_by_indicies(x_train_preclean, keep_indicies)\n",
    "print(\"X train\", x_train.shape)\n",
    "\n",
    "x_test = filter_columns_by_indicies(x_test_preclean, keep_indicies)\n",
    "print(\"X test\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.apply_along_axis(lambda xn: len(set(xn)), 0, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_preclean = np.apply_along_axis(lambda xn: len(set(xn)), 0, x_train_preclean)\n",
    "t_preclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def is_categorical_feature(xn, threshold=20):\n",
    "    return len(set(xn)) < threshold\n",
    "\n",
    "def split_num_cat(data):\n",
    "    is_cat_filter = np.apply_along_axis(is_categorical_feature, 0, data)\n",
    "    cat = data[:, is_cat_filter]\n",
    "    num = data[:, np.logical_not(is_cat_filter)]\n",
    "    return num, cat\n",
    "\n",
    "def one_hot_encode(data):\n",
    "    return data\n",
    "     # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "## 2. Replace the missing values with the mean of the column, add columns \n",
    "def standardize(x):\n",
    "    \"\"\"Standardize the original data set.\"\"\"\n",
    "    return np.nan_to_num((x - np.nanmean(x, axis=0)) / np.nanstd(x, axis=0))\n",
    "\n",
    "\n",
    "def process_data(data):\n",
    "    # col_means = np.nanmean(x, axis=0)\n",
    "    # inds = np.where(np.isnan(x))\n",
    "    # x[inds] = np.take(col_means, inds[1])  # replace columns with values NaN with the mean of that column\n",
    "    # x = (x - np.mean(x)) / np.std(x)  # standarize the data \n",
    "    ## ?? I feel like standardizing by column shouldn't be done like above \n",
    "\n",
    "    x_num, x_cat = split_num_cat(data)\n",
    "    \n",
    "    x_num = standardize(x_num)\n",
    "    x_num = np.c_[np.ones(len(x_num)), x_num]  # add the column of ones\n",
    "    x_cat = one_hot_encode(x_cat)\n",
    "    return x_num, x_cat\n",
    "\n",
    "\n",
    "x_train_std = process_data(x_train)\n",
    "x_test_std = process_data(x_test)\n",
    "print(\"x_train_std shape\", x_train_std.shape)\n",
    "\n",
    "# x_train_2 = process_data(x_train)\n",
    "# x_test_2 = process_data(x_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"# num features: {x_train_std[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yiyuan's test code -- not sure how is this correlation numpy function working\n",
    "# temp = np.array([[1, 2, 7], [19, 58, 37], [-2, 6, 14]])\n",
    "# tempy = np.transpose(np.array([0, 3, -10]))\n",
    "# print(temp)\n",
    "# print(\"y\", tempy)\n",
    "\n",
    "# print(\"correlation is \\n\", np.corrcoef(temp, tempy, rowvar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_correlation(x_train, y_train):\n",
    "    return np.abs(np.corrcoef(x_train, y_train, rowvar=False))\n",
    "\n",
    "cr  =  feature_correlation(x_train_std, y_train)[-1, :-1]\n",
    "plt.hist(cr, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Screen out features based on correlation\n",
    "good_corre_indicies = np.argwhere(cr > 0.05).flatten()\n",
    "print(\"good_corre_indicies\", good_corre_indicies)\n",
    "x_train_corre = x_train_std[:, good_corre_indicies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression *without* regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "initial_w = np.zeros(x_train_corre.shape[1], dtype=np.float128)\n",
    "max_iters = 100\n",
    "gamma = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "## Here the logistic regression is from implementations.py\n",
    "## \n",
    "w, loss = logistic_regression(y_train, x_train_corre, initial_w, max_iters, gamma)\n",
    "print(\"loss is \", loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to predict x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def prediction_labels(weights, data):  ## isn't this for linear regression only ? Don't we need the sigmoid?\n",
    "    \"\"\"Generates class predictions given weights, and a test data matrix.\"\"\"\n",
    "    y_pred = sigmoid(np.dot(data, weights))\n",
    "    y_pred[np.where(y_pred >= 0.5)] = 1\n",
    "    y_pred[np.where(y_pred < 0.5)] = 0\n",
    "    return y_pred\n",
    "\n",
    "y_pred = prediction_labels(w, x_train_corre)\n",
    "temp = y_pred[y_pred != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_train):\n",
    "    return (y_pred == y_train).sum() / len(y_train)\n",
    "def precision(y_pred, y_train):\n",
    "    TP = np.sum((y_train==1) & (y_pred==1))\n",
    "    FP = np.sum((y_train==0) & (y_pred==1))\n",
    "    return TP/(TP+FP)\n",
    "def recall(y_pred, y_train):\n",
    "    recall = np.sum((y_train==1) & (y_pred==1)) / np.sum(y_train==1)\n",
    "    return recall\n",
    "def f_score (y_pred, y_train):\n",
    "    return 2*precision(y_pred, y_train)*recall(y_pred, y_train) / (precision(y_pred, y_train) + recall(y_pred, y_train))\n",
    "\n",
    "print(\"accuracy\", accuracy(y_pred, y_train))\n",
    "print(\"precision\", precision(y_pred, y_train))\n",
    "print(\"recall\", recall(y_pred, y_train))\n",
    "print(\"f_score\", f_score(y_pred, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate trained data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "y_pred = prediction_labels(w, x_test_std[:, good_corre_indicies])\n",
    "y_pred[y_pred == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids, y_pred, 'submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
